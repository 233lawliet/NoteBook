## 正则表达式 ##

### 分类 ###

- 单字符
    - .:除了换行之外所有字符
    - []:匹配集合中的任意字符
    - \d:0~9
    - \D:非0~9
    - \w:数字，字母，下划线，中文
    - \W:非\w
    - \s：所有空白字符
    - \S:非空白字符


- 数量修饰
    - *：任意多次  >=0
    - +:最少一次  >=1
    - ?:可有可无  0次或者1次
    - {m}： 固定m次
    - {m:} ：最少m次
    - {m:n} :m~n次

- 边界
    - \b  \B：边界
    - ^  \A：以什么开头
    - $  \Z：以什么结尾u
 
- 分组
    - () 内部元素设为整体
    - () 优先级
    - () 子模式 



### 糗事百科 ###

    import urllib.request
    import urllib.error
    import re
    import os
    
    
    # url
    url = "https://www.qiushibaike.com/pic/page/"
    
    # headers
    headers = {
        'User-Agent': ' Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36',
        'cookie': 'anonymid=jv7nvww8ty9hrg; depovince=GW; _r01_=1; JSESSIONID=abclLtVL1-PSi9lSfq8Pw; ick_login=a01b335f-d241-4389-9a03-99cdf0a4b22e; t=901333b3b52575122e082975bc91c2d36; societyguester=901333b3b52575122e082975bc91c2d36; id=970648536; xnsid=83bf854c; jebecookies=6135bd0e-2432-4be0-bd08-87c7c966bd27|||||; ver=7.0; loginfrom=null; jebe_key=85140b92-ef07-481d-8a43-1db8bd5a103c%7Caf6966bbcd63631a04b1e1602a140637%7C1556862770762%7C1%7C1556862767115; wp_fold=0'
    }
    
    
    
    
    def downloadImg(content):
        #要的数据()     不要的数据.*?
        pattern=re.compile(r'<div class="thumb">.*?<img src="(.*?)" .*?>.*?</div>',re.S)
        result=pattern.findall(content)
        #处理图片url
        for  index in range(len(result)):
    
    
            result[index]="http:"+result[index]
    
            #创建文件夹
            dirName = "qiutu"
            if not os.path.exists(dirName):
                os.mkdir(dirName)
    
            #捕获文件的名字
            fileName=result[index].split("/")[-1]
            filePath=dirName+"/"+fileName
    
            print("%s正在下载" % (fileName))
            urllib.request.urlretrieve(result[index],filePath)
            print("%s结束下载" % (fileName))
    
    
    
    
    def main():
        startPage=int(input("请输入起始页码："))
        endPage=int(input("请输入结束页码："))
        for page in range(startPage,endPage+1):
    
            #url
            newUrl=url+str(page)
            #request对象
            request=urllib.request.Request(url=newUrl,headers=headers)
            #http handler对象
            handler=urllib.request.HTTPHandler()
            #open对象
            opener=urllib.request.build_opener(handler)
            #响应对象
            response=opener.open(request)
            content=response.read().decode()
    
    
            print("第%d开始下载" % page)
            #下载
            downloadImg(content)
            print("第%d结束下载" %page)
            print("\n")
    
    if __name__ == '__main__':
        main()
    






### 页面的文章标题+链接的文章内容(一点点语录网) ###




    
    import urllib.request
    import urllib.parse
    import re
    
    
    headers={}
    
    #请求获取网页文本
    def getContent(url,headers):
    
        # request
        request = urllib.request.Request(url=url, headers=headers)
    
        # handler
        handler = urllib.request.HTTPHandler()
    
        # opener
        opener = urllib.request.build_opener(handler)
    
        # response
        response = opener.open(request)
    
        # content   原文格式为utf8
        content = response.read().decode()
    
        return content
    
    
    def parseContent(content):
        #内部 href的'"有区别
        #多个括号  捕获的是元组  [0]是第一个元素  [1]是第二个元素
        #findall返回列表
        targetUrl="http://www.yikexun.cn"
    
        pattern=re.compile(r'<h3><a href="(/lizhi/qianming/\d+\.html)"><b>(.*?)</b></a></h3>',re.S)
        result=pattern.findall(content)
    
        for info in result:
            url=targetUrl+info[0]
            title=info[1]
    
            #获取某文章的页面内容
            content=getContent(url=url,headers=headers)
    
    
            #某文章的主体内容  text是list
            patternArticle=re.compile(r'<div class="neirong">(.*?)</div>',re.S)
            text=patternArticle.findall(content)
    
            # 文章主体
            textInfo = ""
            for p in text:
                textInfo = textInfo + p
    
            # 去除图片
            patternRemoveImg = re.compile(r"<img .*?>")
            textInfo = patternRemoveImg.sub('', textInfo)
    
    
    
            article ="<h1>%s</h1>%s" %(title,textInfo)
            #编入的编码
            with open("lizhi.html","a",encoding="utf8") as f:
                f.write(article)
    
    
    
    
    def main():
        startPage=int(input("请输入你的开始页码："))
        endPage=int(input("请输入你的结束页码："))
        url="http://www.yikexun.cn/lizhi/qianming/list_50_"
        for page in  range(startPage,endPage+1):
            #请求信息
            newUrl=url +str(page) +".html"
    
    
            #获取文本
            content=getContent(newUrl,headers)
    
            #匹配
            parseContent(content)
    
    
    
    if __name__ == '__main__':
        main()









- 